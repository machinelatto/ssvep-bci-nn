{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4916c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from braindecode.models import EEGNetv4\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d51b4",
   "metadata": {},
   "source": [
    "# DNN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSVEPDNN(nn.Module):\n",
    "    def __init__(self, num_classes=40, channels=9, samples=250, subbands=3):\n",
    "        super(SSVEPDNN, self).__init__()\n",
    "        # [batch, subbands, channels, time]\n",
    "        # Subband combination layer\n",
    "        self.subband_combination = nn.Conv2d(\n",
    "            subbands, 1, kernel_size=(1, 1), bias=False\n",
    "        )\n",
    "        # Channel combination layer\n",
    "        self.channel_combination = nn.Conv2d(1, 120, kernel_size=(channels, 1))\n",
    "        # First dropout\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        # Third layer - Time convolution\n",
    "        self.third_conv = nn.Conv2d(120, 120, kernel_size=(1, 2), stride=(1, 2))\n",
    "        # Second droput\n",
    "        self.drop2 = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # 4th conv - FIR filtering\n",
    "        self.fourth_conv = nn.Conv2d(120, 120, kernel_size=(1, 10), padding=\"same\")\n",
    "        self.drop3 = nn.Dropout(0.95)\n",
    "\n",
    "        # Fully connected layer - Classifier\n",
    "        self.fc = nn.Linear(120 * (samples // 2), num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            self.subband_combination.weight.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, subbands, channels, time]\n",
    "        x = self.subband_combination(x)  # [batch, 1, channels, time]\n",
    "        x = self.channel_combination(x)  # [batch, 120, 1, time]\n",
    "        x = self.drop1(x)\n",
    "        x = self.third_conv(x)  # [batch, 120, 1, time/2]\n",
    "        x = self.drop2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fourth_conv(x)  # [batch, 120, 1, time/2]\n",
    "        x = self.drop3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)  # [batch, num_classes]\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb44c88",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7880581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_subject_utils import (\n",
    "    plot_learning_curves,\n",
    "    evaluate,\n",
    "    get_windows,\n",
    "    load_data_from_users,\n",
    "    get_windows,\n",
    "    filter_signals_subbands,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cca import CCA_otimizacao, matriz_referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9734782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=100,\n",
    "    device=0,\n",
    "    save_path=\"best_model.pth\",\n",
    "):\n",
    "    best_val_accuracy = -float(\"inf\")\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    for epoch in tqdm.notebook.tqdm(range(num_epochs)):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # eval train\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # eval validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.inference_mode():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # val accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Save if best vall acc\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            # print(f\"Best model saved with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs}: \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "        )\n",
    "    plot_learning_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778394c",
   "metadata": {},
   "source": [
    "# Cross Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd048c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_phase_path = (\n",
    "    \"C:/Users/machi/Documents/Mestrado/repos/data/benchmark/Freq_Phase.mat\"\n",
    ")\n",
    "freq_phase = scipy.io.loadmat(freq_phase_path)\n",
    "frequencias = np.round(freq_phase[\"freqs\"], 2).ravel()\n",
    "fases = freq_phase[\"phases\"]\n",
    "\n",
    "# Parâmetros do pré-processamento\n",
    "sample_rate = 250\n",
    "delay = 160\n",
    "\n",
    "# Parâmetros do CCA\n",
    "num_harmonica = 5\n",
    "inform_fase = 0\n",
    "\n",
    "# Parâmetros de janelas e sessões\n",
    "tamanho_da_janela_seg = 1\n",
    "tamanho_da_janela = int(np.ceil(tamanho_da_janela_seg * sample_rate))\n",
    "\n",
    "occipital_electrodes = np.array([47, 53, 54, 55, 56, 57, 60, 61, 62])\n",
    "frequencias_desejadas = frequencias[:8]\n",
    "indices = [np.where(frequencias == freq)[0][0] for freq in frequencias_desejadas]\n",
    "\n",
    "# Usuários\n",
    "# users = list(range(1, 36))  # Usuários de 1 a 35\n",
    "users = list(range(1, 11))  # Usuários de 1 a 10\n",
    "\n",
    "epochs = 300\n",
    "exp_dir = Path(\n",
    "    f\"CCA_dnn_3_subband_independent/{len(users)}_users_{len(frequencias_desejadas)}_freqs_{tamanho_da_janela_seg}_s/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Usuários de interesse:\", users)\n",
    "print(f\"Frequencies used: {frequencias_desejadas}\")\n",
    "print(f\"Frequencies indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_data_from_users(\n",
    "    users,\n",
    "    visual_delay=delay,\n",
    "    filter_bandpass=False,\n",
    "    sample_rate=sample_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668e35f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Cross-Subject EEGNet Training (single window per trial, no window separation)\n",
    "metricas_usuarios = []\n",
    "exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare cross-subject splits\n",
    "for test_user_idx, test_user in enumerate(users):\n",
    "    print(f\"Processando Usuário {test_user}\")\n",
    "    train_users = [u for u in users if u != test_user]\n",
    "    print(f\"Train Users: {train_users}\")\n",
    "\n",
    "    # Concatenate training data from all train_users\n",
    "    train_data = np.concatenate(\n",
    "        [all_data[users.index(u)] for u in train_users], axis=-1\n",
    "    )  # shape: (channels, samples, freqs, trials)\n",
    "    test_data = all_data[test_user_idx]\n",
    "\n",
    "    num_canais, _, num_freqs, num_trials_train = train_data.shape\n",
    "    num_trials_test = test_data.shape[-1]\n",
    "\n",
    "    # Prepare reference matrices for all frequencies (no window separation)\n",
    "    Y_train = np.zeros(\n",
    "        (tamanho_da_janela * num_trials_train, num_harmonica * 2, len(indices))\n",
    "    )\n",
    "    Y_test = np.zeros(\n",
    "        (tamanho_da_janela * num_trials_test, num_harmonica * 2, len(indices))\n",
    "    )\n",
    "    for k in indices:\n",
    "        print(k)\n",
    "        print(\n",
    "            f\"Generating reference for frequency index {k}, frequency {frequencias[k]} Hz\"\n",
    "        )\n",
    "        y_train = matriz_referencia(\n",
    "            num_harmonica,\n",
    "            inform_fase,\n",
    "            num_trials_train,\n",
    "            frequencias[k],\n",
    "            fases,\n",
    "            tamanho_da_janela,\n",
    "        )\n",
    "        Y_train[:, :, k] = y_train\n",
    "        print(f\"Y_train shape after freq {frequencias[k]} Hz: {Y_train.shape}\")\n",
    "        y_test = matriz_referencia(\n",
    "            num_harmonica,\n",
    "            inform_fase,\n",
    "            num_trials_test,\n",
    "            frequencias[k],\n",
    "            fases,\n",
    "            tamanho_da_janela,\n",
    "        )\n",
    "        Y_test[:, :, k] = y_test\n",
    "        print(f\"Y_test shape after freq {frequencias[k]} Hz: {Y_test.shape}\")\n",
    "\n",
    "    X_train = np.zeros(\n",
    "        (\n",
    "            tamanho_da_janela * num_trials_train,\n",
    "            3,\n",
    "            len(occipital_electrodes),\n",
    "            len(indices),\n",
    "        )\n",
    "    )\n",
    "    X_test = np.zeros(\n",
    "        (\n",
    "            tamanho_da_janela * num_trials_test,\n",
    "            3,\n",
    "            len(occipital_electrodes),\n",
    "            len(indices),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for k in range(len(indices)):\n",
    "        # For training: each trial is a single window\n",
    "        eeg_matrix_train = train_data[\n",
    "            occipital_electrodes, :tamanho_da_janela, indices[k], :\n",
    "        ].reshape(-1, len(occipital_electrodes), tamanho_da_janela)\n",
    "        eeg_matrix_train = filter_signals_subbands(\n",
    "            eeg_matrix_train, subban_no=3, sampling_rate=250\n",
    "        )\n",
    "        eeg_matrix_test = test_data[\n",
    "            occipital_electrodes, :tamanho_da_janela, indices[k], :\n",
    "        ].reshape(-1, len(occipital_electrodes), tamanho_da_janela)\n",
    "        eeg_matrix_test = filter_signals_subbands(\n",
    "            eeg_matrix_test, subban_no=3, sampling_rate=250\n",
    "        )\n",
    "\n",
    "        eeg_matrix_train = np.moveaxis(eeg_matrix_train, -1, 0)\n",
    "        eeg_matrix_test = np.moveaxis(eeg_matrix_test, -1, 0)\n",
    "        eeg_matrix_train = np.concatenate(eeg_matrix_train, axis=0)\n",
    "        eeg_matrix_test = np.concatenate(eeg_matrix_test, axis=0)\n",
    "\n",
    "        X_train[:, :, :, k] = eeg_matrix_train\n",
    "        X_test[:, :, :, k] = eeg_matrix_test\n",
    "\n",
    "    # # CCA optimization (across all training data)\n",
    "    Combinadores_Y = []\n",
    "    Combinadores_X = []\n",
    "    for i in range(3):\n",
    "        Combinadores_Y_sub = []\n",
    "        Combinadores_X_sub = []\n",
    "        for k in range(len(indices)):\n",
    "            Wx, Wy, _ = CCA_otimizacao(X_train[:, i, :, k], Y_train[:, :, k])\n",
    "            Combinadores_Y_sub.append(Wy)\n",
    "            Combinadores_X_sub.append(Wx)\n",
    "        Combinadores_X.append(np.column_stack(Combinadores_X_sub))\n",
    "        Combinadores_Y.append(np.column_stack(Combinadores_Y_sub))\n",
    "    Combinadores_X = np.array(Combinadores_X)  # shape: (3, len(indices), channels)\n",
    "    Combinadores_Y = np.array(\n",
    "        Combinadores_Y\n",
    "    )  # shape: (3, len(indices), 2*num_harmonica)\n",
    "\n",
    "    # Separar em janelas\n",
    "    X_teste_janelas = []\n",
    "    X_treino_janelas = []\n",
    "    Y_teste_janelas = []\n",
    "    Y_treino_janelas = []\n",
    "\n",
    "    for k in range(len(indices)):\n",
    "        X_t, numero_janelas_teste = get_windows(\n",
    "            X_test[:, :, :, k], tamanho_da_janela, include_last=False\n",
    "        )\n",
    "        Y_t, _ = get_windows(Y_test[:, :, k], tamanho_da_janela, include_last=False)\n",
    "\n",
    "        X_v, numero_janelas_treino = get_windows(\n",
    "            X_train[:, :, :, k], tamanho_da_janela, include_last=False\n",
    "        )\n",
    "        Y_v, _ = get_windows(Y_train[:, :, k], tamanho_da_janela, include_last=False)\n",
    "\n",
    "        X_teste_janelas.append(X_t)\n",
    "        Y_teste_janelas.append(Y_t)\n",
    "\n",
    "        X_treino_janelas.append(X_v)\n",
    "        Y_treino_janelas.append(Y_v)\n",
    "\n",
    "    # Construir tensor de treinamento\n",
    "    rotulos_treinamento = []\n",
    "    tensor_treinamento = np.zeros(\n",
    "        [len(indices) * num_trials_train, 3, len(indices), tamanho_da_janela]\n",
    "    )\n",
    "    cont = 0\n",
    "\n",
    "    for m in range(len(indices)):\n",
    "        for j in range(numero_janelas_treino):\n",
    "            rotulos_treinamento.append(frequencias[indices[m]])\n",
    "            cont_1 = 0\n",
    "            for w in range(len(indices)):\n",
    "                for subband in range(3):\n",
    "                    Wx = Combinadores_X[subband, :, w]\n",
    "                    janela_x = X_treino_janelas[m][j][:, subband, :]\n",
    "                    projecao_x = np.dot(Wx, janela_x.T)\n",
    "                    tensor_treinamento[cont, subband, cont_1, :] = projecao_x\n",
    "\n",
    "                cont_1 += 1\n",
    "            cont += 1\n",
    "\n",
    "    rotulos_teste = []\n",
    "    tensor_teste = np.zeros(\n",
    "        [len(indices) * num_trials_test, 3, len(indices), tamanho_da_janela]\n",
    "    )\n",
    "    cont = 0\n",
    "\n",
    "    for m in range(len(indices)):\n",
    "        for j in range(numero_janelas_teste):\n",
    "            rotulos_teste.append(frequencias[indices[m]])\n",
    "            cont_1 = 0\n",
    "            for w in range(len(indices)):\n",
    "                for subband in range(3):\n",
    "                    Wx = Combinadores_X[subband, :, w]\n",
    "                    janela_x = X_teste_janelas[m][j][:, subband, :]\n",
    "                    projecao_x = np.dot(Wx, janela_x.T)\n",
    "                    tensor_teste[cont, subband, cont_1, :] = projecao_x\n",
    "\n",
    "                cont_1 += 1\n",
    "            cont += 1\n",
    "\n",
    "    # Map labels to indices\n",
    "    mapeamento = {rotulo: i for i, rotulo in enumerate(sorted(frequencias_desejadas))}\n",
    "    rotulos_treinamento = torch.tensor(\n",
    "        [\n",
    "            mapeamento[rotulo.item()] if hasattr(rotulo, \"item\") else mapeamento[rotulo]\n",
    "            for rotulo in rotulos_treinamento\n",
    "        ]\n",
    "    )\n",
    "    rotulos_teste = torch.tensor(\n",
    "        [\n",
    "            mapeamento[rotulo.item()] if hasattr(rotulo, \"item\") else mapeamento[rotulo]\n",
    "            for rotulo in rotulos_teste\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_treino = torch.tensor(tensor_treinamento, dtype=torch.float32).to(device)\n",
    "    X_teste = torch.tensor(tensor_teste, dtype=torch.float32).to(device)\n",
    "    Y_treino = torch.tensor(rotulos_treinamento, dtype=torch.long).to(device)\n",
    "    Y_teste = torch.tensor(rotulos_teste, dtype=torch.long).to(device)\n",
    "    print(\"X_train:\", X_treino.shape)\n",
    "    print(\"X_test:\", X_teste.shape)\n",
    "    print(\"Y_train:\", Y_treino.shape)\n",
    "    print(\"Y_test:\", Y_teste.shape)\n",
    "\n",
    "    # Model setup\n",
    "    model = SSVEPDNN(\n",
    "        num_classes=len(frequencias_desejadas),\n",
    "        channels=8,\n",
    "        samples=tamanho_da_janela,\n",
    "        subbands=3,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    dataset = TensorDataset(X_treino, Y_treino)\n",
    "    train_size = int(0.85 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(X_teste, Y_teste), batch_size=10, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    best_model = train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs=epochs,\n",
    "        device=device,\n",
    "        save_path=exp_dir.joinpath(f\"best_model_user_{test_user}.pth\"),\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy, recall, f1, cm = evaluate(best_model, test_loader)\n",
    "\n",
    "    metricas_usuarios.append(\n",
    "        {\n",
    "            \"usuario\": test_user,\n",
    "            \"acuracia\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"f1-score\": f1,\n",
    "            \"confusion_matrix\": cm,\n",
    "        }\n",
    "    )\n",
    "    print(\n",
    "        f\"Test User {test_user} Finished: Accuracy={accuracy:.4f}, Recall={recall:.4f}, F1={f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Salvar as métricas de cada usuário\n",
    "    df_metricas = pd.DataFrame(metricas_usuarios)\n",
    "    df_metricas.to_csv(exp_dir.joinpath(\"metricas.csv\"), index=False)\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9568b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "\n",
    "# # Cross-Subject EEGNet Training (single window per trial, no window separation)\n",
    "# metricas_usuarios = []\n",
    "# exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Prepare cross-subject splits\n",
    "# for test_user_idx, test_user in enumerate(users):\n",
    "#     print(f\"Processando Usuário {test_user}\")\n",
    "#     train_users = [u for u in users if u != test_user]\n",
    "#     print(f\"Train Users: {train_users}\")\n",
    "\n",
    "#     # Concatenate training data from all train_users\n",
    "#     train_data = np.concatenate(\n",
    "#         [all_data[users.index(u)] for u in train_users], axis=-1\n",
    "#     )  # shape: (channels, samples, freqs, trials)\n",
    "#     test_data = all_data[test_user_idx]\n",
    "\n",
    "#     num_canais, _, num_freqs, num_trials_train = train_data.shape\n",
    "#     num_trials_test = test_data.shape[-1]\n",
    "\n",
    "#     # Prepare reference matrices for all frequencies (no window separation)\n",
    "#     Y_train = np.zeros(\n",
    "#         (tamanho_da_janela * num_trials_train, num_harmonica * 2, len(indices))\n",
    "#     )\n",
    "#     Y_test = np.zeros(\n",
    "#         (tamanho_da_janela * num_trials_test, num_harmonica * 2, len(indices))\n",
    "#     )\n",
    "#     for k in indices:\n",
    "#         print(k)\n",
    "#         print(\n",
    "#             f\"Generating reference for frequency index {k}, frequency {frequencias[k]} Hz\"\n",
    "#         )\n",
    "#         y_train = matriz_referencia(\n",
    "#             num_harmonica,\n",
    "#             inform_fase,\n",
    "#             num_trials_train,\n",
    "#             frequencias[k],\n",
    "#             fases,\n",
    "#             tamanho_da_janela,\n",
    "#         )\n",
    "#         Y_train[:, :, k] = y_train\n",
    "#         print(f\"Y_train shape after freq {frequencias[k]} Hz: {Y_train.shape}\")\n",
    "#         y_test = matriz_referencia(\n",
    "#             num_harmonica,\n",
    "#             inform_fase,\n",
    "#             num_trials_test,\n",
    "#             frequencias[k],\n",
    "#             fases,\n",
    "#             tamanho_da_janela,\n",
    "#         )\n",
    "#         Y_test[:, :, k] = y_test\n",
    "#         print(f\"Y_test shape after freq {frequencias[k]} Hz: {Y_test.shape}\")\n",
    "\n",
    "#     X_train = np.zeros(\n",
    "#         (tamanho_da_janela * num_trials_train, len(occipital_electrodes), len(indices))\n",
    "#     )\n",
    "#     X_test = np.zeros(\n",
    "#         (tamanho_da_janela * num_trials_test, len(occipital_electrodes), len(indices))\n",
    "#     )\n",
    "\n",
    "#     for k in range(len(indices)):\n",
    "#         # For training: each trial is a single window\n",
    "#         eeg_matrix_train = train_data[\n",
    "#             occipital_electrodes, :tamanho_da_janela, indices[k], :\n",
    "#         ]\n",
    "#         # filter_signals_subbands(eeg_matrix_train, subban_no=3, sampling_rate=250)\n",
    "#         eeg_matrix_test = test_data[\n",
    "#             occipital_electrodes, :tamanho_da_janela, indices[k], :\n",
    "#         ]\n",
    "#         # filter_signals_subbands(eeg_matrix_test, subban_no=3, sampling_rate=250)\n",
    "\n",
    "#         # Transpõe os dados para que cada linha represente uma amostra\n",
    "#         eeg_matrix_train = np.transpose(eeg_matrix_train)\n",
    "#         eeg_matrix_test = np.transpose(eeg_matrix_test)\n",
    "#         eeg_matrix_train = np.concatenate(eeg_matrix_train, axis=0)\n",
    "#         eeg_matrix_test = np.concatenate(eeg_matrix_test, axis=0)\n",
    "\n",
    "#         X_train[:, :, k] = eeg_matrix_train\n",
    "#         X_test[:, :, k] = eeg_matrix_test\n",
    "\n",
    "#     # CCA optimization (across all training data)\n",
    "#     Combinadores_Y = []\n",
    "#     Combinadores_X = []\n",
    "#     correlacoes_max = []\n",
    "#     for k in range(len(indices)):\n",
    "#         Wx, Wy, corr = CCA_otimizacao(X_train[:, :, k], Y_train[:, :, k])\n",
    "#         Combinadores_Y.append(Wy)\n",
    "#         Combinadores_X.append(Wx)\n",
    "#         correlacoes_max.append(corr)\n",
    "#     Combinadores_X = np.column_stack(Combinadores_X)\n",
    "#     Combinadores_Y = np.column_stack(Combinadores_Y)\n",
    "\n",
    "#     # Separar em janelas\n",
    "#     X_teste_janelas = []\n",
    "#     X_treino_janelas = []\n",
    "#     Y_teste_janelas = []\n",
    "#     Y_treino_janelas = []\n",
    "\n",
    "#     for k in range(len(indices)):\n",
    "#         X_t, numero_janelas_teste = get_windows(\n",
    "#             X_test[:, :, k], tamanho_da_janela, include_last=False\n",
    "#         )\n",
    "#         Y_t, _ = get_windows(Y_test[:, :, k], tamanho_da_janela, include_last=False)\n",
    "\n",
    "#         X_v, numero_janelas_treino = get_windows(\n",
    "#             X_train[:, :, k], tamanho_da_janela, include_last=False\n",
    "#         )\n",
    "#         Y_v, _ = get_windows(Y_train[:, :, k], tamanho_da_janela, include_last=False)\n",
    "\n",
    "#         X_teste_janelas.append(X_t)\n",
    "#         Y_teste_janelas.append(Y_t)\n",
    "\n",
    "#         X_treino_janelas.append(X_v)\n",
    "#         Y_treino_janelas.append(Y_v)\n",
    "\n",
    "#     # Construir tensor de treinamento\n",
    "#     rotulos_treinamento = []\n",
    "#     tensor_treinamento = np.zeros(\n",
    "#         [len(indices) * num_trials_train, len(indices), tamanho_da_janela]\n",
    "#     )\n",
    "#     cont = 0\n",
    "\n",
    "#     for m in range(len(indices)):\n",
    "#         for j in range(numero_janelas_treino):\n",
    "#             janela_x = X_treino_janelas[m][j]\n",
    "#             rotulos_treinamento.append(frequencias[indices[m]])\n",
    "#             cont_1 = 0\n",
    "#             for w in range(len(indices)):\n",
    "#                 Wx = Combinadores_X[:, w]\n",
    "\n",
    "#                 projecao_x = np.dot(Wx, janela_x.T)\n",
    "#                 tensor_treinamento[cont, cont_1, :] = projecao_x\n",
    "\n",
    "#                 cont_1 += 1\n",
    "#             cont += 1\n",
    "\n",
    "#     rotulos_teste = []\n",
    "#     tensor_teste = np.zeros(\n",
    "#         [len(indices) * num_trials_test, len(indices), tamanho_da_janela]\n",
    "#     )\n",
    "#     cont = 0\n",
    "\n",
    "#     for m in range(len(indices)):\n",
    "#         for j in range(numero_janelas_teste):\n",
    "#             janela_x = X_teste_janelas[m][j]\n",
    "#             rotulos_teste.append(frequencias[indices[m]])\n",
    "#             cont_1 = 0\n",
    "\n",
    "#             for w in range(len(indices)):\n",
    "#                 Wx = Combinadores_X[:, w]\n",
    "\n",
    "#                 projecao_x = np.dot(Wx, janela_x.T)\n",
    "#                 tensor_teste[cont, cont_1, :] = projecao_x\n",
    "\n",
    "#                 cont_1 += 1\n",
    "#             cont += 1\n",
    "\n",
    "#     # Map labels to indices\n",
    "#     mapeamento = {rotulo: i for i, rotulo in enumerate(sorted(frequencias_desejadas))}\n",
    "#     rotulos_treinamento = torch.tensor(\n",
    "#         [\n",
    "#             mapeamento[rotulo.item()] if hasattr(rotulo, \"item\") else mapeamento[rotulo]\n",
    "#             for rotulo in rotulos_treinamento\n",
    "#         ]\n",
    "#     )\n",
    "#     rotulos_teste = torch.tensor(\n",
    "#         [\n",
    "#             mapeamento[rotulo.item()] if hasattr(rotulo, \"item\") else mapeamento[rotulo]\n",
    "#             for rotulo in rotulos_teste\n",
    "#         ]\n",
    "#     )\n",
    "#     tensor_treinamento = filter_signals_subbands(\n",
    "#         tensor_treinamento, subban_no=1, sampling_rate=250\n",
    "#     )\n",
    "#     tensor_teste = filter_signals_subbands(tensor_teste, subban_no=1, sampling_rate=250)\n",
    "\n",
    "#     X_treino = torch.tensor(tensor_treinamento, dtype=torch.float32).to(device)\n",
    "#     X_teste = torch.tensor(tensor_teste, dtype=torch.float32).to(device)\n",
    "#     Y_treino = torch.tensor(rotulos_treinamento, dtype=torch.long).to(device)\n",
    "#     Y_teste = torch.tensor(rotulos_teste, dtype=torch.long).to(device)\n",
    "#     print(\"X_train:\", X_treino.shape)\n",
    "#     print(\"X_test:\", X_teste.shape)\n",
    "#     print(\"Y_train:\", Y_treino.shape)\n",
    "#     print(\"Y_test:\", Y_teste.shape)\n",
    "\n",
    "#     # Model setup\n",
    "#     model = SSVEPDNN(\n",
    "#         num_classes=len(frequencias_desejadas),\n",
    "#         channels=8,\n",
    "#         samples=tamanho_da_janela,\n",
    "#         subbands=1,\n",
    "#     )\n",
    "#     model = model.to(device)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#     dataset = TensorDataset(X_treino, Y_treino)\n",
    "#     train_size = int(0.85 * len(dataset))\n",
    "#     val_size = len(dataset) - train_size\n",
    "#     train_dataset, val_dataset = random_split(\n",
    "#         dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed)\n",
    "#     )\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "#     test_loader = DataLoader(\n",
    "#         TensorDataset(X_teste, Y_teste), batch_size=10, shuffle=False\n",
    "#     )\n",
    "\n",
    "#     # Train\n",
    "#     best_model = train(\n",
    "#         model,\n",
    "#         train_loader,\n",
    "#         val_loader,\n",
    "#         criterion,\n",
    "#         optimizer,\n",
    "#         num_epochs=epochs,\n",
    "#         device=device,\n",
    "#         save_path=exp_dir.joinpath(f\"best_model_user_{test_user}.pth\"),\n",
    "#     )\n",
    "\n",
    "#     # Evaluate\n",
    "#     accuracy, recall, f1, cm = evaluate(best_model, test_loader)\n",
    "\n",
    "#     metricas_usuarios.append(\n",
    "#         {\n",
    "#             \"usuario\": test_user,\n",
    "#             \"acuracia\": accuracy,\n",
    "#             \"recall\": recall,\n",
    "#             \"f1-score\": f1,\n",
    "#             \"confusion_matrix\": cm,\n",
    "#         }\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"Test User {test_user} Finished: Accuracy={accuracy:.4f}, Recall={recall:.4f}, F1={f1:.4f}\"\n",
    "#     )\n",
    "\n",
    "#     # Salvar as métricas de cada usuário\n",
    "# df_metricas = pd.DataFrame(metricas_usuarios)\n",
    "#     df_metricas.to_csv(exp_dir.joinpath(\"metricas.csv\"), index=False)\n",
    "\n",
    "#     print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
