{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b81f870f90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from braindecode.models import EEGNetv4\n",
    "import copy\n",
    "import random\n",
    "\n",
    "seed = 102\n",
    "\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Curva de Perda\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Perda Treinamento\")\n",
    "    plt.plot(epochs, val_losses, label=\"Perda Validação\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Curva de Perda: Treino e validação\")\n",
    "\n",
    "    # Curva de Acurácia\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Acurácia Treinamento\")\n",
    "    plt.plot(epochs, val_accuracies, label=\"Acurácia Validação\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Acurácia (%)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Curva de Acurácia: Treino e validação\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, chanels):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test set Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    classes = np.unique(np.concatenate((all_labels, all_preds)))\n",
    "\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    # fig, ax = plt.subplots(figsize=(15, 15))  # aumenta a figura\n",
    "    # disp.plot(ax=ax, cmap=\"Blues\", xticks_rotation=\"vertical\")  # rotaciona os rótulos para caber melhor\n",
    "    # plt.show()\n",
    "\n",
    "    print(all_labels)\n",
    "    print(all_preds)\n",
    "\n",
    "    return accuracy, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(\n",
    "    dados, taxa_amostragem, freq_corte_low, freq_corte_high, ordem_filtro\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Filtra dados EEG utilizando um filtro Butterworth passa-banda.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Parâmetros:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dados (ndarray): Dados do EEG com formato (número de eletrodos, número de amostras, número de frequências, número de trials).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    taxa_amostragem (int): Frequência de amostragem dos sinais EEG (Hz).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    freq_corte_low (float): Frequência de corte inferior do filtro passa-banda (Hz).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    freq_corte_high (float): Frequência de corte superior do filtro passa-banda (Hz).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ordem_filtro (int): Ordem do filtro Butterworth.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Retorna:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ndarray: Dados EEG filtrados.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # **Construção do filtro passa-banda**\n",
    "\n",
    "    # Cria o filtro passa-banda com os parâmetros especificados\n",
    "\n",
    "    b, a = signal.butter(\n",
    "        ordem_filtro,\n",
    "        [freq_corte_low, freq_corte_high],\n",
    "        btype=\"bandpass\",\n",
    "        analog=False,\n",
    "        output=\"ba\",\n",
    "        fs=taxa_amostragem,\n",
    "    )\n",
    "\n",
    "    # **Filtragem dos dados**\n",
    "\n",
    "    # Realiza o processo de filtragem para todas as frequências, trials e eletrodos\n",
    "\n",
    "    num_eletrodos, num_amostras, num_freqs, num_trials = dados.shape\n",
    "\n",
    "    filtered_data = np.zeros_like(dados)\n",
    "\n",
    "    # Filtra os dados para cada frequência, trial e eletrodo\n",
    "\n",
    "    for f in range(num_freqs):  # Para cada frequência de estimulação\n",
    "\n",
    "        for trial in range(num_trials):  # Para cada trial\n",
    "\n",
    "            for eletrodo in range(num_eletrodos):  # Para cada eletrodo\n",
    "\n",
    "                # Filtra o sinal com o filtro de fase zero\n",
    "\n",
    "                eletrodo_filtrado = signal.filtfilt(b, a, dados[eletrodo, :, f, trial])\n",
    "\n",
    "                # Substitui o dado original pelo filtrado\n",
    "\n",
    "                filtered_data[eletrodo, :, f, trial] = eletrodo_filtrado\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCA_otimizacao(X, Y):\n",
    "\n",
    "    # Calcula as linhas e colunas da matriz X\n",
    "    linhas_X, colunas_X = X.shape\n",
    "    # O número de amostras da matriz X é igual ao número de linhas de X\n",
    "    num_amostras = linhas_X\n",
    "    # Concatena X e Y\n",
    "    V = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "    # Calcula a matriz S, matriz de covariância de X e Y.\n",
    "    S = (1 / num_amostras) * (\n",
    "        V.T @ V\n",
    "        - (1 / num_amostras)\n",
    "        * V.T\n",
    "        @ np.ones((num_amostras, 1))\n",
    "        @ np.ones((1, num_amostras))\n",
    "        @ V\n",
    "    )\n",
    "\n",
    "    # Autocovariância de X\n",
    "    Cxx = S[:colunas_X, :colunas_X]\n",
    "    # Autocovariância de Y\n",
    "    Cyy = S[colunas_X:, colunas_X:]\n",
    "    # Covariância entre X e Y\n",
    "    Cxy = S[:colunas_X, colunas_X:]\n",
    "\n",
    "    # Calcula os autovalores e os autovetores de Cxx\n",
    "    autovalores, autovetores = np.linalg.eig(Cxx)\n",
    "\n",
    "    # Calcula a raiz quadrada dos autovalores\n",
    "    raiz_autovalores = np.sqrt(autovalores)\n",
    "\n",
    "    # Constrói a matriz diagonal dos autovalores\n",
    "    raiz_lambda = np.diag(raiz_autovalores)\n",
    "\n",
    "    # Calcula a inversa da matriz de autovetores\n",
    "    inv_autovetores = np.linalg.inv(autovetores)\n",
    "\n",
    "    # Calcula a raiz quadrada da matriz Cxx\n",
    "    raiz_Cxx = np.dot(np.dot(autovetores, raiz_lambda), inv_autovetores)\n",
    "\n",
    "    # Calcula a inversa da matriz raiz quadrada\n",
    "    inv_raiz_Cxx = np.linalg.inv(raiz_Cxx)\n",
    "\n",
    "    # Calcula os autovalores e os autovetores de Cyy\n",
    "    autovalores, autovetores = np.linalg.eig(Cyy)\n",
    "\n",
    "    # Calcula a raiz quadrada dos autovalores\n",
    "    raiz_autovalores = np.sqrt(autovalores)\n",
    "\n",
    "    # Constrói a matriz diagonal dos autovalores\n",
    "    raiz_lambda = np.diag(raiz_autovalores)\n",
    "\n",
    "    # Calcula a inversa da matriz de autovetores\n",
    "    inv_autovetores = np.linalg.inv(autovetores)\n",
    "\n",
    "    # Calcula a raiz quadrada da matriz Cyy\n",
    "    raiz_Cyy = np.dot(np.dot(autovetores, raiz_lambda), inv_autovetores)\n",
    "\n",
    "    # Calcula a inversa da matriz raiz quadrada\n",
    "    inv_raiz_Cyy = np.linalg.inv(raiz_Cyy)\n",
    "\n",
    "    # Calcula a matriz Kappa\n",
    "    K = np.dot(inv_raiz_Cxx, np.dot(Cxy, inv_raiz_Cyy))\n",
    "\n",
    "    # Decomposição da matriz Kappa, usando o método de decomposição em valores singulares\n",
    "    Gamma, Lambda, Delta = np.linalg.svd(K)\n",
    "\n",
    "    # Inversa da matriz Delta\n",
    "    Delta = Delta.T\n",
    "\n",
    "    # Calcula os combinadores lineares Wx e Wy.\n",
    "    Wx = np.dot(inv_raiz_Cxx, Gamma[:, 0])\n",
    "    Wy = np.dot(inv_raiz_Cyy, Delta[:, 0])\n",
    "\n",
    "    correlation = Lambda[0]\n",
    "\n",
    "    # Retorna os combinadores lineares.\n",
    "    return Wx, Wy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_referencia(\n",
    "    numero_de_harmonicas, fase_inicial, sessoes, frequencia, fase, numero_de_amostras\n",
    "):\n",
    "\n",
    "    # Taxa de amostragem\n",
    "\n",
    "    dt = 1 / 250\n",
    "\n",
    "    # Número de amostras\n",
    "\n",
    "    n = np.arange(numero_de_amostras)\n",
    "\n",
    "    # Vetor de tempo\n",
    "\n",
    "    t = dt * n\n",
    "\n",
    "    y = []\n",
    "\n",
    "    if fase_inicial == 0:\n",
    "\n",
    "        theta = 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        theta = fase\n",
    "\n",
    "    # Gerando sinais senoidais e cossenoidais\n",
    "\n",
    "    for k in range(1, numero_de_harmonicas + 1):\n",
    "\n",
    "        y1 = np.sin(2 * np.pi * k * frequencia * t + theta)\n",
    "\n",
    "        y2 = np.cos(2 * np.pi * k * frequencia * t + theta)\n",
    "\n",
    "        y.append(y1)\n",
    "\n",
    "        y.append(y2)\n",
    "\n",
    "    # Transpõe o array Y\n",
    "    y = np.array(y)\n",
    "    y = np.transpose(y)\n",
    "\n",
    "    # Repete o array para coincidir com o número de sessões\n",
    "\n",
    "    Y = np.tile(y, (sessoes, 1))\n",
    "\n",
    "    # Retorna a Matriz de sinais de referência\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_eeg(dados, sessoes_treino, eletrodos, indice_freq):\n",
    "    # Inicializa a lista para armazenar os dados de treinamento\n",
    "    X_treino = []\n",
    "\n",
    "    # Itera sobre as sessões de treinamento\n",
    "    for secao in sessoes_treino:\n",
    "        # Adiciona os dados da sessão atual à lista\n",
    "        X_treino.append(dados[eletrodos, :, indice_freq, secao])\n",
    "\n",
    "    # Concatena os dados ao longo do eixo das colunas\n",
    "    X_treino = np.concatenate(X_treino, axis=1)\n",
    "    # Transpõe os dados para que cada linha represente uma amostra\n",
    "    X_treino = np.transpose(X_treino)\n",
    "\n",
    "    return X_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_em_janelas(matriz, tamanho_janela, incluir_ultimo=False):\n",
    "    # Calcular o número total de linhas\n",
    "    total_linhas = matriz.shape[0]\n",
    "\n",
    "    # Calcular o número de grupos necessário\n",
    "    num_janelas = total_linhas // tamanho_janela + (\n",
    "        1 if total_linhas % tamanho_janela != 0 else 0\n",
    "    )\n",
    "\n",
    "    # Inicializar uma lista vazia para armazenar os grupos\n",
    "    janelas = []\n",
    "\n",
    "    # Iterar sobre a matriz, pegando as linhas de tamanho_grupo em tamanho_grupo e armazenando em grupos\n",
    "    for i in range(0, total_linhas, tamanho_janela):\n",
    "        janela = matriz[i : i + tamanho_janela]  # Pegar o grupo de tamanho_grupo linhas\n",
    "        janelas.append(janela)  # Adicionar o grupo à lista\n",
    "\n",
    "    # Se incluir_ultimo for False e houver linhas restantes, remover o último grupo\n",
    "    if not incluir_ultimo and total_linhas % tamanho_janela != 0:\n",
    "        janelas.pop()\n",
    "\n",
    "    return janelas, num_janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=100,\n",
    "    device=0,\n",
    "    save_path=\"best_model_raw.pth\",\n",
    "):\n",
    "    best_val_accuracy = 0.0\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # eval train\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # eval validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.inference_mode():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # val accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Save if best vall acc\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            # print(f\"Best model saved with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    #     print(\n",
    "    #         f\"Epoch {epoch + 1}/{num_epochs}: \"\n",
    "    #         f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "    #         f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "    #         )\n",
    "    # plot_learning_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencias_e_fases = scipy.io.loadmat(\n",
    "    \"C:/Users/machi/Documents/Mestrado/repos/data/benchmark/Freq_Phase.mat\"\n",
    ")\n",
    "\n",
    "\n",
    "frequencias = frequencias_e_fases[\"freqs\"]\n",
    "\n",
    "\n",
    "frequencias = np.round(frequencias, 2).ravel()\n",
    "\n",
    "\n",
    "fases = frequencias_e_fases[\"phases\"]\n",
    "\n",
    "\n",
    "filter_order = 10\n",
    "\n",
    "\n",
    "freq_cut_high = 70\n",
    "\n",
    "\n",
    "freq_cut_low = 6\n",
    "\n",
    "\n",
    "sample_rate = 250\n",
    "\n",
    "\n",
    "num_harmonica = 5\n",
    "\n",
    "\n",
    "delay = 160  # 160 amostras, 0,5s (sem estimulação) + 0,14s (latencia para começo da evocação)\n",
    "\n",
    "inform_fase = 0\n",
    "\n",
    "\n",
    "tamanho_da_janela = 1\n",
    "\n",
    "\n",
    "tamanho_da_janela = int(np.ceil(tamanho_da_janela * sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  9., 10., 11., 12., 13., 14., 15.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencias[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando Usuário 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\machi\\AppData\\Local\\Temp\\ipykernel_22612\\2503681362.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_treino = torch.tensor(rotulos_treinamento, dtype=torch.long).to(\n",
      "C:\\Users\\machi\\AppData\\Local\\Temp\\ipykernel_22612\\2503681362.py:176: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_teste = torch.tensor(rotulos_teste, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (8 x 251). Kernel size: (40 x 1). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 210\u001b[0m\n\u001b[0;32m    205\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    206\u001b[0m     TensorDataset(X_teste, Y_teste), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    207\u001b[0m )\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Treinar\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m best_model \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    211\u001b[0m     model, train_loader, val_loader, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Avaliar\u001b[39;00m\n\u001b[0;32m    215\u001b[0m accuracy, recall, f1 \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m    216\u001b[0m     best_model, test_loader, chanels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(frequencias_desejadas)\n\u001b[0;32m    217\u001b[0m )\n",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\braindecode\\models\\eegnet.py:24\u001b[0m, in \u001b[0;36mConv2dWithConstraint.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrenorm(\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, maxnorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm\n\u001b[0;32m     23\u001b[0m     )\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(Conv2dWithConstraint, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mforward(x)\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\machi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (8 x 251). Kernel size: (40 x 1). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "metricas_usuarios = []\n",
    "\n",
    "for user in range(1, 2):\n",
    "    file_path = f\"C:/Users/machi/Documents/Mestrado/repos/data/benchmark/S{user}.mat\"\n",
    "    print(f\"Processando Usuário {user}\")\n",
    "\n",
    "    # Carregar e preparar dados\n",
    "    data = scipy.io.loadmat(file_path)[\"data\"]\n",
    "    data = bandpass_filter(data, sample_rate, freq_cut_low, freq_cut_high, filter_order)\n",
    "    data = data[:, (delay) : (delay + 1250), :, :]\n",
    "\n",
    "    occipital_electrodes = np.array([47, 53, 54, 55, 56, 57, 60, 61, 62])\n",
    "    frequencias_desejadas = frequencias[:8]\n",
    "    indices = [np.where(frequencias == freq)[0][0] for freq in frequencias_desejadas]\n",
    "\n",
    "    num_canais, num_amostras, num_freqs, num_sections = data.shape\n",
    "\n",
    "    metricas_crossval = []\n",
    "\n",
    "    # Leave-one-session-out cross-validation\n",
    "    for sessao_teste in range(6):  # 6 sessões no total\n",
    "        sessoes_treino = [s for s in range(6) if s != sessao_teste]\n",
    "        sessoes_teste = [sessao_teste]\n",
    "\n",
    "        # Preparar os dados de treino\n",
    "        Y_treino = np.zeros(\n",
    "            (len(sessoes_treino) * num_amostras, num_harmonica * 2, len(indices))\n",
    "        )\n",
    "        for k in indices:\n",
    "            y_treino = matriz_referencia(\n",
    "                num_harmonica,\n",
    "                inform_fase,\n",
    "                len(sessoes_treino),\n",
    "                frequencias[k],\n",
    "                fases,\n",
    "                num_amostras,\n",
    "            )\n",
    "            Y_treino[:, :, k] = y_treino\n",
    "\n",
    "        X_treino = np.zeros(\n",
    "            (\n",
    "                len(sessoes_treino) * num_amostras,\n",
    "                len(occipital_electrodes),\n",
    "                len(indices),\n",
    "            )\n",
    "        )\n",
    "        for k in range(len(indices)):\n",
    "            x_treino = matriz_eeg(\n",
    "                data, sessoes_treino, occipital_electrodes, indices[k]\n",
    "            )\n",
    "            X_treino[:, :, k] = x_treino\n",
    "\n",
    "        # Preparar os dados de teste\n",
    "        Y_teste = np.zeros(\n",
    "            (len(sessoes_teste) * num_amostras, num_harmonica * 2, len(indices))\n",
    "        )\n",
    "        for k in indices:\n",
    "            y_test = matriz_referencia(\n",
    "                num_harmonica,\n",
    "                inform_fase,\n",
    "                len(sessoes_teste),\n",
    "                frequencias[k],\n",
    "                fases,\n",
    "                num_amostras,\n",
    "            )\n",
    "            Y_teste[:, :, k] = y_test\n",
    "\n",
    "        X_teste = np.zeros(\n",
    "            (len(sessoes_teste) * num_amostras, len(occipital_electrodes), len(indices))\n",
    "        )\n",
    "        for k in range(len(indices)):\n",
    "            x_test = matriz_eeg(data, sessoes_teste, occipital_electrodes, indices[k])\n",
    "            X_teste[:, :, k] = x_test\n",
    "\n",
    "        # Otimização CCA\n",
    "        Combinadores_Y = []\n",
    "        Combinadores_X = []\n",
    "        correlacoes_max = []\n",
    "        for k in range(len(indices)):\n",
    "            Wx, Wy, corr = CCA_otimizacao(X_treino[:, :, k], Y_treino[:, :, k])\n",
    "            Combinadores_Y.append(Wy)\n",
    "            Combinadores_X.append(Wx)\n",
    "            correlacoes_max.append(corr)\n",
    "\n",
    "        Combinadores_X = np.column_stack(Combinadores_X)\n",
    "        Combinadores_Y = np.column_stack(Combinadores_Y)\n",
    "\n",
    "        # Separar em janelas\n",
    "        X_teste_janelas = []\n",
    "        X_treino_janelas = []\n",
    "        Y_teste_janelas = []\n",
    "        Y_treino_janelas = []\n",
    "\n",
    "        for k in range(len(indices)):\n",
    "            X_t, numero_janelas_teste = separar_em_janelas(\n",
    "                X_teste[:, :, k], tamanho_da_janela, incluir_ultimo=False\n",
    "            )\n",
    "            Y_t, _ = separar_em_janelas(\n",
    "                Y_teste[:, :, k], tamanho_da_janela, incluir_ultimo=False\n",
    "            )\n",
    "\n",
    "            X_v, numero_janelas_treino = separar_em_janelas(\n",
    "                X_treino[:, :, k], tamanho_da_janela, incluir_ultimo=False\n",
    "            )\n",
    "            Y_v, _ = separar_em_janelas(\n",
    "                Y_treino[:, :, k], tamanho_da_janela, incluir_ultimo=False\n",
    "            )\n",
    "\n",
    "            X_teste_janelas.append(X_t)\n",
    "            Y_teste_janelas.append(Y_t)\n",
    "\n",
    "            X_treino_janelas.append(X_v)\n",
    "            Y_treino_janelas.append(Y_v)\n",
    "\n",
    "        # Construir tensor de treinamento\n",
    "        rotulos_treinamento = []\n",
    "        tensor_treinamento = np.zeros(\n",
    "            [5 * len(indices) * len(sessoes_treino), len(indices), tamanho_da_janela]\n",
    "        )\n",
    "        cont = 0\n",
    "\n",
    "        for m in range(len(indices)):\n",
    "            for j in range(numero_janelas_treino):\n",
    "                janela_x = X_treino_janelas[m][j]\n",
    "                rotulos_treinamento.append(frequencias[indices[m]])\n",
    "                cont_1 = 0\n",
    "                for w in range(len(indices)):\n",
    "                    Wx = Combinadores_X[:, w]\n",
    "\n",
    "                    projecao_x = np.dot(Wx, janela_x.T)\n",
    "                    tensor_treinamento[cont, cont_1, :] = projecao_x\n",
    "\n",
    "                    cont_1 += 1\n",
    "                cont += 1\n",
    "\n",
    "        rotulos_teste = []\n",
    "        tensor_teste = np.zeros(\n",
    "            [5 * len(indices) * len(sessoes_teste), len(indices), tamanho_da_janela]\n",
    "        )\n",
    "        cont = 0\n",
    "\n",
    "        for m in range(len(indices)):\n",
    "\n",
    "            for j in range(numero_janelas_teste):\n",
    "                janela_x = X_teste_janelas[m][j]\n",
    "                rotulos_teste.append(frequencias[indices[m]])\n",
    "                cont_1 = 0\n",
    "\n",
    "                for w in range(len(indices)):\n",
    "                    Wx = Combinadores_X[:, w]\n",
    "\n",
    "                    projecao_x = np.dot(Wx, janela_x.T)\n",
    "                    tensor_teste[cont, cont_1, :] = projecao_x\n",
    "\n",
    "                    cont_1 += 1\n",
    "                cont += 1\n",
    "\n",
    "        mapeamento = {\n",
    "            rotulo: i for i, rotulo in enumerate(sorted(frequencias_desejadas))\n",
    "        }\n",
    "\n",
    "        rotulos_treinamento = torch.tensor(\n",
    "            [mapeamento[rotulo.item()] for rotulo in rotulos_treinamento]\n",
    "        )\n",
    "        rotulos_teste = torch.tensor(\n",
    "            [mapeamento[rotulo.item()] for rotulo in rotulos_teste]\n",
    "        )\n",
    "\n",
    "        X_treino = torch.tensor(tensor_treinamento, dtype=torch.float32).to(\n",
    "            device\n",
    "        )  # Converte para tensor float\n",
    "        X_teste = torch.tensor(tensor_teste, dtype=torch.float32).to(device)\n",
    "        Y_treino = torch.tensor(rotulos_treinamento, dtype=torch.long).to(\n",
    "            device\n",
    "        )  # Converte para tensor long (categorias)\n",
    "        Y_teste = torch.tensor(rotulos_teste, dtype=torch.long).to(device)\n",
    "\n",
    "        np.save(f\"cca_subj_{user}_session_{sessao_teste}_train.npy\", tensor_treinamento)\n",
    "        np.save(\n",
    "            f\"cca_subj_{user}_session_{sessao_teste}_labels_train.npy\", Y_treino.cpu()\n",
    "        )\n",
    "        np.save(f\"cca_subj_{user}_session_{sessao_teste}_test.npy\", tensor_teste)\n",
    "        np.save(\n",
    "            f\"cca_subj_{user}_session_{sessao_teste}_labels_test.npy\", Y_teste.cpu()\n",
    "        )\n",
    "        # Aqui você monta o modelo\n",
    "        model = EEGNetv4(n_chans=40, n_outputs=40, n_times=250)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        dataset = TensorDataset(X_treino, Y_treino)\n",
    "        train_size = int(0.85 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "\n",
    "        train_dataset, val_dataset = random_split(\n",
    "            dataset,\n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(seed),\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "        test_loader = DataLoader(\n",
    "            TensorDataset(X_teste, Y_teste), batch_size=10, shuffle=False\n",
    "        )\n",
    "\n",
    "        # Treinar\n",
    "        best_model = train(\n",
    "            model, train_loader, val_loader, criterion, optimizer, num_epochs=1000\n",
    "        )\n",
    "\n",
    "        # Avaliar\n",
    "        accuracy, recall, f1 = evaluate(\n",
    "            best_model, test_loader, chanels=len(frequencias_desejadas)\n",
    "        )\n",
    "\n",
    "        metricas_crossval.append(\n",
    "            {\n",
    "                \"usuario\": user,\n",
    "                \"sessao_teste\": sessao_teste,\n",
    "                \"acuracia\": accuracy,\n",
    "                \"recall\": recall,\n",
    "                \"f1-score\": f1,\n",
    "            }\n",
    "        )\n",
    "        print(\n",
    "            f\"Usuário {user} - Sessão {sessao_teste} Finalizada: Acurácia={accuracy:.4f}, Recall={recall:.4f}, F1={f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Salvar todas as sessões do usuário\n",
    "    metricas_usuarios.extend(metricas_crossval)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# =====================================\n",
    "# Mostrar resultados finais detalhados\n",
    "# =====================================\n",
    "\n",
    "print(\"\\nResultados Finais Detalhados por Usuário e Sessão:\")\n",
    "print(\"=\" * 50)\n",
    "for resultado in metricas_usuarios:\n",
    "    print(\n",
    "        f\"Usuário {resultado['usuario']} - Sessão {resultado['sessao_teste']}: \"\n",
    "        f\"Acurácia = {resultado['acuracia']:.4f}, \"\n",
    "        f\"Recall = {resultado['recall']:.4f}, \"\n",
    "        f\"F1-Score = {resultado['f1-score']:.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
